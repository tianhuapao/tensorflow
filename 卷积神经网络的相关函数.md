### 卷积神经网络的相关函数

在```TensorFlow```中，使用```tf.nn.conv2d```来实现卷积操作，使用```tf.nn.max_pool```进行最大池化操作。通过传入不同的参数，来实现各种不同类型的卷积与池化操作。下面介绍这两个函数中各参数的具体意义。

#### 卷积函数tf.nn,conv2d

在```TensorFlow```里使用```tf.nn.conv2d```函数来实现卷积，其格式如下：

```
tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, name=None)
```

除去参数name参数用以指定该操作的name，与方法有关的共有5个参数。

- input：指需要做卷积的输入图像，它要求是一个Tensor，具有[batch，in_height，in_width，in_channels]这样的形状（shape），具体含义是“训练时一个batch的图片数量，图片高度，图片宽度，图像通道数”，注意这是一个四维的Tensor，要求类型为```float32```和```float64```其中之一。
- filter：相当于CNN中的卷积核，它要求是一个Tensor，具有[filter_height，filter_width，in_channels，out_channels]这样的shape，具体含义是“卷积核的高度，滤波器的宽度，图像通道数，滤波器个数”，要求类型与参数input相同。有一个地方需要注意，第三维in_channels，就是参数input的第四维。
- strides：卷积时在图像每一维的步长，这是一个一维的向量，长度为4。
- padding：定义元素边框与元素内容之间的空间。string类型的量，只能是SAME和VALID其中之一，这个值决定了不同的卷积方式，padding的值为'VALID'时，表示边缘不填充，当其为'SAME'时，表示填充到滤波器可以到达图像边缘。
- ```use_cudnn_on_gpu：bool```类型，是否使用```cudnn```加速，默认为true。
- 返回值：```tf.nn.conr2d```函数结果返回一个Tensor，这个输出就是常说的feature map。

**注意：**在卷积函数中，padding参数是最容易引起歧义的，该参数仅仅决定是否要补0，因此一定要清楚padding设为SAME的真正含义。在设为SAME的情况下，只有在步长为1时生成的feature map才会与输入值相等。



####　padding规则介绍

padding属性的意义是定义元素边框与元素内容之间的空间。

在```tf.nn.conv2d```函数中，当变量padding为VALID和SAME时，函数具体是怎么计算的呢？其实是有公式的。为了方便演示，先来定义几个变量：

- 输入的尺寸中高和宽定义成in_height、in_width。
- 卷积核的高和宽定义成filter_height、filter_width。
- 输出的尺寸中高和宽定义成output_height、output_width。
- 步长的高宽方向定义成strides_height、strides_ width。

#####　VALID情况

输出宽和高的公式代码分别为：

```
output_width=(in_width–filter_width + 1)/strides_ width（结果向上取整）
output_height=(in_height–filter_height+1)/strides_height（结果向上取整）
```

##### SAME情况

输出的宽和高将与卷积核没有关系，具体公式代码如下：

```
out_height = in_height / strides_height（结果向上取整）
out_width = in_width / strides_ width（结果向上取整）
```

这里有一个很重要的知识点——补零的规则，见如下代码：

```
pad_height=max((out_height-1)×strides_height +filter_height-in_height,0)
pad_width = max((out_width-1)×strides_ width +filter_width - in_width, 0)
pad_top = pad_height / 2
pad_bottom = pad _height - pad_top
pad_left = pad _width / 2
pad_right = pad _width - pad_left

```

上面代码中:

- pad_height：代表高度方向要填充0的行数。
- pad_width：代表宽度方向要填充0的列数。
- pad_top、pad_bottom、pad_left、pad_right：分别代表上、下、左、右这4个方向填充0的行、列数。

##### 规则举例

下面通过例子来理解一下padding规则。

假设用一个一维数据来举例，输入是13，filter是6，步长是5，对于padding的取值有如下表示：

```
VALID'相当于padding，生成的宽度为（13-6+1）/5 = 2（向上取整）个数字。
   inputs:         1  2  3  4  5  6  7  8  9  10  11  (12 13)
                 |________________|                  dropped
                               |_________________|
```

'SAME'=相当于padding，生成的宽度为13/5=3（向上取整）个数字。

Padding的方式可以如下计算：

```
Pad_width = (3-1) ×5+6-13 = 3
Pad_left = pad_width/2= 3/2 = 1
Pad_rigth = pad_width-pad_left = 2

```

在左边补一个0，右边补2个0。

```
 pad|                                          | pad
   inputs:      0 | 1  2  3  4  5  6  7  8  9  10  11  12  13 | 0  0  
              |________________|
                            |_________________|
                                           |_____________________|
```

### 卷积函数的使用

下面通过一个例子来介绍卷积函数的用法。

通过手动生成一个5×5的矩阵来模拟图片，定义一个2×2的卷积核，来测试tf.nn.conv2d函数里的不同参数，验证其输出结果。

在这个例子中，分为如下几个步骤来写代码。

（1）定义输入变量。

（2）定义卷积核变量。

（3）定义卷积操作。

（4）运行卷积操作。

下面就来一一操作。

#### 定义输入变量

定义3个输入变量用来模拟输入图片，分别是5×5大小1个通道的矩阵、5×5大小2个通道的矩阵、4×4大小1个通道的矩阵，并将里面的值统统赋为1。

```
import tensorflow as tf
# [batch, in_height, in_width, in_channels] [训练时一个批次的图片数量,图片高度,图片宽度, 图像通道数]  

input = tf.Variable(tf.constant(1.0,shape = [1, 5, 5, 1]))
input2 = tf.Variable(tf.constant(1.0,shape = [1, 5, 5, 2]))
input3 = tf.Variable(tf.constant(1.0,shape = [1, 4, 4, 1]))
```

#### 定义卷积核变量

定义5个卷积核，每个卷积核都是2×2的矩阵，只是输入、输出的通道数有差别，分别为```1ch```输入、```1ch```输出，```1ch```输入、```2ch```输出，```1ch```输入、```3ch```输出，```2ch```输入、```2ch```输出，```2ch```输入、```1ch``输出，并分别在里面填入指定的数值：

```python
# [filter_height, filter_width, in_channels, out_channels]（卷积核的高度，卷积核的宽
# 度，图像通道数，卷积核个数）

filter1 =  tf.Variable(tf.constant([-1.0,0,0,-1],shape = [2, 2, 1, 1]))
filter2 =  tf.Variable(tf.constant([-1.0,0,0,-1,-1.0,0,0,-1],shape = 
[2, 2, 1, 2])) 
filter3 =  tf.Variable(tf.constant([-1.0,0,0,-1,-1.0,0,0,-1,-1.0,
0,0,-1],shape = [2, 2, 1, 3])) 
filter4 =  tf.Variable(tf.constant([-1.0,0,0,-1,
                                    -1.0,0,0,-1,
                                    -1.0,0,0,-1,                                    -1.0,0,0,-1],shape = [2, 2, 2, 2])) 
filter5 =  tf.Variable(tf.constant([-1.0,0,0,-1,-1.0,0,0,-1],shape = 
[2, 2, 2, 1]))

```



#### 定义卷积操作

